{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy import stats\n",
    "from scipy.stats import boxcox\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in Data\n",
    "train = pd.read_csv('dataFiles/application_train.csv')\n",
    "test = pd.read_csv('dataFiles/application_test.csv')\n",
    "bureau_data = pd.read_csv('dataFiles/bureau.csv')\n",
    "bureau_balance_data = pd.read_csv('dataFiles/bureau_balance.csv')\n",
    "prev_app_data = pd.read_csv('dataFiles/previous_application.csv')\n",
    "pos_cash_balance_data = pd.read_csv('dataFiles/POS_CASH_balance.csv')\n",
    "installments_data = pd.read_csv('dataFiles/installments_payments.csv')\n",
    "cc_data = pd.read_csv('dataFiles/credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train.select_dtypes(exclude='object')\n",
    "test_num = test.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Transformations\n",
    "train_num[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY',\\\n",
    "       'AMT_GOODS_PRICE']] = np.log(train_num[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']])\n",
    "\n",
    "test_num[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY',\\\n",
    "       'AMT_GOODS_PRICE']] = np.log(test_num[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clipping Outliers\n",
    "train_num['CNT_CHILDREN'] = train_num['CNT_CHILDREN'].apply(lambda x: 5 if x >=5 else x)\n",
    "train_num['CNT_FAM_MEMBERS'] = train_num['CNT_FAM_MEMBERS'].apply(lambda x: 5 if x >=5 else x)\n",
    "train_num['AMT_INCOME_TOTAL'] = train_num['AMT_INCOME_TOTAL'].apply(lambda x: 14 if x >=14 else x)\n",
    "train_num['HOUR_APPR_PROCESS_START'] = train_num['HOUR_APPR_PROCESS_START'].apply(lambda x: 2 if x <= 2 else x)\n",
    "train_num['COMMONAREA_AVG'] = train_num['COMMONAREA_AVG'].fillna(0).apply(lambda x: 0.3 if x >= 0.3 else x)\n",
    "train_num['AMT_REQ_CREDIT_BUREAU_YEAR'] = train_num['AMT_REQ_CREDIT_BUREAU_YEAR'].apply(lambda x: 9 if x >= 9 else x).fillna(10)\n",
    "\n",
    "test_num['CNT_CHILDREN'] = test_num['CNT_CHILDREN'].apply(lambda x: 5 if x >=5 else x)\n",
    "test_num['CNT_FAM_MEMBERS'] = test_num['CNT_FAM_MEMBERS'].apply(lambda x: 5 if x >=5 else x)\n",
    "test_num['AMT_INCOME_TOTAL'] = test_num['AMT_INCOME_TOTAL'].apply(lambda x: 14 if x >=14 else x)\n",
    "test_num['HOUR_APPR_PROCESS_START'] = test_num['HOUR_APPR_PROCESS_START'].apply(lambda x: 2 if x <= 2 else x)\n",
    "test_num['COMMONAREA_AVG'] = test_num['COMMONAREA_AVG'].fillna(0).apply(lambda x: 0.3 if x >= 0.3 else x)\n",
    "test_num['AMT_REQ_CREDIT_BUREAU_YEAR'] = test_num['AMT_REQ_CREDIT_BUREAU_YEAR'].apply(lambda x: 9 if x >= 9 else x).fillna(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINNING THE TWO HUMPS FROM DAYS_EMPLOYED\n",
    "train_num['DAYS_EMPLOYED_BIN_1'] = train_num['DAYS_EMPLOYED'].apply(lambda x: 1 if x < 150000 else 0)\n",
    "train_num['DAYS_EMPLOYED_BIN_2'] = train_num['DAYS_EMPLOYED'].apply(lambda x: 1 if x >= 150000 else 0)\n",
    "\n",
    "#BINNING THE TWO HUMPS FROM DAYS_EMPLOYED\n",
    "test_num['DAYS_EMPLOYED_BIN_1'] = test_num['DAYS_EMPLOYED'].apply(lambda x: 1 if x < 150000 else 0)\n",
    "test_num['DAYS_EMPLOYED_BIN_2'] = test_num['DAYS_EMPLOYED'].apply(lambda x: 1 if x >= 150000 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABS & BOX COX Transformation\n",
    "train_num['DAYS_REGISTRATION'] = np.abs(train_num['DAYS_REGISTRATION'])\n",
    "train_num['DAYS_REGISTRATION'] = train_num['DAYS_REGISTRATION'].apply(lambda x: 0.01 if x == 0 else x)\n",
    "train_num['DAYS_REGISTRATION'] = boxcox(train_num['DAYS_REGISTRATION'],0.5)\n",
    "\n",
    "train_num['DAYS_ID_PUBLISH'] = np.abs(train_num['DAYS_ID_PUBLISH'])\n",
    "train_num['DAYS_ID_PUBLISH'] = train_num['DAYS_ID_PUBLISH'].apply(lambda x: 0.01 if x == 0 else x)\n",
    "train_num['DAYS_ID_PUBLISH'] = boxcox(train_num['DAYS_ID_PUBLISH'],0.5)\n",
    "\n",
    "train_num['ENTRANCES_AVG'] = train_num['ENTRANCES_AVG'].apply(lambda x: np.sqrt(x) if pd.notnull(x) else x)\n",
    "\n",
    "test_num['DAYS_REGISTRATION'] = np.abs(test_num['DAYS_REGISTRATION'])\n",
    "test_num['DAYS_REGISTRATION'] = test_num['DAYS_REGISTRATION'].apply(lambda x: 0.01 if x == 0 else x)\n",
    "test_num['DAYS_REGISTRATION'] = boxcox(test_num['DAYS_REGISTRATION'],0.5)\n",
    "\n",
    "test_num['DAYS_ID_PUBLISH'] = np.abs(test_num['DAYS_ID_PUBLISH'])\n",
    "test_num['DAYS_ID_PUBLISH'] = test_num['DAYS_ID_PUBLISH'].apply(lambda x: 0.01 if x == 0 else x)\n",
    "test_num['DAYS_ID_PUBLISH'] = boxcox(test_num['DAYS_ID_PUBLISH'],0.5)\n",
    "\n",
    "test_num['ENTRANCES_AVG'] = test_num['ENTRANCES_AVG'].apply(lambda x: np.sqrt(x) if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Bins for Own Car Age\n",
    "def own_car_age_bins(x):\n",
    "    if pd.isnull(x):\n",
    "        return 0\n",
    "    elif x <= 10:\n",
    "        return 1\n",
    "    elif x <= 30:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "train['OWN_CAR_AGE_BINS'] = train['OWN_CAR_AGE'].apply(own_car_age_bins)\n",
    "\n",
    "test['OWN_CAR_AGE_BINS'] = test['OWN_CAR_AGE'].apply(own_car_age_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['FLAG_MOBIL' 'FLAG_CONT_MOBILE' 'FLAG_DOCUMENT_2' 'FLAG_DOCUMENT_4'\n 'FLAG_DOCUMENT_7' 'FLAG_DOCUMENT_10' 'FLAG_DOCUMENT_12'\n 'FLAG_DOCUMENT_15' 'FLAG_DOCUMENT_17' 'FLAG_DOCUMENT_19'\n 'FLAG_DOCUMENT_20' 'FLAG_DOCUMENT_21' 'OWN_CAR_AGE'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-f5877ecc706a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Columns to drop because of sparse features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FLAG_MOBIL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_CONT_MOBILE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_4'\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;34m'FLAG_DOCUMENT_7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_12'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_15'\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;34m'FLAG_DOCUMENT_17'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_19'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_20'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'OWN_CAR_AGE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DAYS_EMPLOYED'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DAYS_EMPLOYED_BIN_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FLAG_MOBIL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_CONT_MOBILE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_4'\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;34m'FLAG_DOCUMENT_7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_12'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_15'\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;34m'FLAG_DOCUMENT_17'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_19'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_20'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAG_DOCUMENT_21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'OWN_CAR_AGE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DAYS_EMPLOYED'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DAYS_EMPLOYED_BIN_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MikeTodisco/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MikeTodisco/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MikeTodisco/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['FLAG_MOBIL' 'FLAG_CONT_MOBILE' 'FLAG_DOCUMENT_2' 'FLAG_DOCUMENT_4'\n 'FLAG_DOCUMENT_7' 'FLAG_DOCUMENT_10' 'FLAG_DOCUMENT_12'\n 'FLAG_DOCUMENT_15' 'FLAG_DOCUMENT_17' 'FLAG_DOCUMENT_19'\n 'FLAG_DOCUMENT_20' 'FLAG_DOCUMENT_21' 'OWN_CAR_AGE'] not contained in axis"
     ]
    }
   ],
   "source": [
    "#Columns to drop because of sparse features\n",
    "train_num = train_num.drop(['FLAG_MOBIL','FLAG_CONT_MOBILE','FLAG_DOCUMENT_2','FLAG_DOCUMENT_4',\\\n",
    "                    'FLAG_DOCUMENT_7','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12','FLAG_DOCUMENT_15',\\\n",
    "                    'FLAG_DOCUMENT_17','FLAG_DOCUMENT_19','FLAG_DOCUMENT_20','FLAG_DOCUMENT_21','OWN_CAR_AGE','DAYS_EMPLOYED','DAYS_EMPLOYED_BIN_1'], axis = 1)\n",
    "\n",
    "test_num = test_num.drop(['FLAG_MOBIL','FLAG_CONT_MOBILE','FLAG_DOCUMENT_2','FLAG_DOCUMENT_4',\\\n",
    "                    'FLAG_DOCUMENT_7','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12','FLAG_DOCUMENT_15',\\\n",
    "                    'FLAG_DOCUMENT_17','FLAG_DOCUMENT_19','FLAG_DOCUMENT_20','FLAG_DOCUMENT_21','OWN_CAR_AGE','DAYS_EMPLOYED','DAYS_EMPLOYED_BIN_1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FillNA Columns\n",
    "train_num[['APARTMENTS_AVG','BASEMENTAREA_AVG','YEARS_BEGINEXPLUATATION_AVG','YEARS_BUILD_AVG','ELEVATORS_AVG','ENTRANCES_AVG',\\\n",
    "       'AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\\\n",
    "       'AMT_REQ_CREDIT_BUREAU_QRT','OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE',\\\n",
    "       'DEF_60_CNT_SOCIAL_CIRCLE','EXT_SOURCE_1',\\\n",
    "       'EXT_SOURCE_2','EXT_SOURCE_3']] = train_num[['APARTMENTS_AVG','BASEMENTAREA_AVG','YEARS_BEGINEXPLUATATION_AVG','YEARS_BUILD_AVG',\\\n",
    "                                             'ELEVATORS_AVG','ENTRANCES_AVG','AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY',\\\n",
    "                                             'AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT',\\\n",
    "                                              'OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',\\\n",
    "                                              'EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']].fillna(0)\n",
    "\n",
    "test_num[['APARTMENTS_AVG','BASEMENTAREA_AVG','YEARS_BEGINEXPLUATATION_AVG','YEARS_BUILD_AVG','ELEVATORS_AVG','ENTRANCES_AVG','AMT_REQ_CREDIT_BUREAU_HOUR',\\\n",
    "      'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT',\\\n",
    "      'OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','EXT_SOURCE_1',\\\n",
    "       'EXT_SOURCE_2','EXT_SOURCE_3']] = test[['APARTMENTS_AVG','BASEMENTAREA_AVG','YEARS_BEGINEXPLUATATION_AVG',\\\n",
    "                                  'YEARS_BUILD_AVG','ELEVATORS_AVG','ENTRANCES_AVG','AMT_REQ_CREDIT_BUREAU_HOUR',\\\n",
    "                                              'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\\\n",
    "                                              'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT',\\\n",
    "                                             'OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',\\\n",
    "                                             'EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train_num.fillna(0)\n",
    "\n",
    "test_num = test_num.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold for NAs\n",
    "train_num_subset = train_num.dropna(thresh=len(train_num) - 0, axis = 1).drop(['TARGET','SK_ID_CURR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num_subset = test_num[train_num_subset.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_num_subset)\n",
    "train_num_scaled = scaler.transform(train_num_subset)\n",
    "test_num_scaled = scaler.transform(test_num_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "# gbm_param_grid = {\n",
    "#     'subsample': np.arange(.05, 1, .05),\n",
    "#     'max_depth': np.arange(3, 20, 1),\n",
    "#     'colsample_bytree': np.arange(.1,1.05, .05)\n",
    "# }\n",
    "\n",
    "# randomized_neg_mse = RandomizedSearchCV(estimator = xgb_model,\n",
    "#                                        param_distributions = gbm_param_grid, n_iter = 10, \n",
    "#                                        scoring = 'neg_mean_squared_error', cv = 4)\n",
    "\n",
    "# randomized_neg_mse.fit(train_num_scaled, train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=100,\n",
       "       nthread=-1, objective='binary:logistic', seed=0, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(train_num_scaled, train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(xgb_model.predict_proba(test_num_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb = pd.concat([test.SK_ID_CURR, preds], axis=1).drop(0, axis = 1)\n",
    "submission_xgb.columns = ['SK_ID_CURR', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb.to_csv('submission_xgb_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_sample(train_num_scaled, train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 282686, 1: 282686})\n"
     ]
    }
   ],
   "source": [
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = pd.get_dummies(train[['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\\\n",
    "'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FONDKAPREMONT_MODE','HOUSETYPE_MODE','WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE']]).fillna(0)\n",
    "\n",
    "test_dummies = pd.get_dummies(test[['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\\\n",
    "'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FONDKAPREMONT_MODE','HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE']]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = train_dummies.drop(['CODE_GENDER_M','CODE_GENDER_XNA','FLAG_OWN_CAR_N','FLAG_OWN_REALTY_N',\\\n",
    "                    'NAME_TYPE_SUITE_Children','NAME_TYPE_SUITE_Group of people','NAME_TYPE_SUITE_Other_A',\\\n",
    "                    'NAME_TYPE_SUITE_Other_B','NAME_INCOME_TYPE_Businessman','NAME_INCOME_TYPE_Maternity leave',\\\n",
    "                   'NAME_INCOME_TYPE_Student','NAME_INCOME_TYPE_Unemployed','NAME_EDUCATION_TYPE_Academic degree',\\\n",
    "                   'NAME_EDUCATION_TYPE_Incomplete higher','NAME_EDUCATION_TYPE_Lower secondary',\\\n",
    "                   'NAME_FAMILY_STATUS_Unknown','NAME_HOUSING_TYPE_Co-op apartment','NAME_HOUSING_TYPE_Municipal apartment',\\\n",
    "                   'NAME_HOUSING_TYPE_Office apartment','NAME_HOUSING_TYPE_Rented apartment','NAME_HOUSING_TYPE_With parents',\\\n",
    "                   'FONDKAPREMONT_MODE_not specified','FONDKAPREMONT_MODE_org spec account','HOUSETYPE_MODE_specific housing',\\\n",
    "                   'HOUSETYPE_MODE_terraced house','WALLSMATERIAL_MODE_Block','WALLSMATERIAL_MODE_Mixed','WALLSMATERIAL_MODE_Monolithic',\\\n",
    "                   'WALLSMATERIAL_MODE_Others','WALLSMATERIAL_MODE_Wooden','EMERGENCYSTATE_MODE_Yes'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = test_dummies.drop(['CODE_GENDER_M','FLAG_OWN_CAR_N','FLAG_OWN_REALTY_N',\\\n",
    "                    'NAME_TYPE_SUITE_Children','NAME_TYPE_SUITE_Group of people','NAME_TYPE_SUITE_Other_A',\\\n",
    "                    'NAME_TYPE_SUITE_Other_B','NAME_INCOME_TYPE_Businessman',\\\n",
    "                   'NAME_INCOME_TYPE_Student','NAME_INCOME_TYPE_Unemployed','NAME_EDUCATION_TYPE_Academic degree',\\\n",
    "                   'NAME_EDUCATION_TYPE_Incomplete higher','NAME_EDUCATION_TYPE_Lower secondary',\\\n",
    "                   'NAME_HOUSING_TYPE_Co-op apartment','NAME_HOUSING_TYPE_Municipal apartment',\\\n",
    "                   'NAME_HOUSING_TYPE_Office apartment','NAME_HOUSING_TYPE_Rented apartment','NAME_HOUSING_TYPE_With parents',\\\n",
    "                   'FONDKAPREMONT_MODE_not specified','FONDKAPREMONT_MODE_org spec account','HOUSETYPE_MODE_specific housing',\\\n",
    "                   'HOUSETYPE_MODE_terraced house','WALLSMATERIAL_MODE_Block','WALLSMATERIAL_MODE_Mixed','WALLSMATERIAL_MODE_Monolithic',\\\n",
    "                   'WALLSMATERIAL_MODE_Others','WALLSMATERIAL_MODE_Wooden','EMERGENCYSTATE_MODE_Yes'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fields to impute\n",
    "'AMT_ANNUITY','AMT_GOODS_PRICE','CNT_FAM_MEMBERS',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer()\n",
    "imputer.fit(train_subset)\n",
    "train_merged_imputed = pd.DataFrame(imputer.transform(train_subset), columns = train_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_subset = train_merged.dropna(thresh=len(train) - 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select_dtypes(exclude='object').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bureau Balance ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_data_grouped = pd.get_dummies(bureau_balance_data).groupby('SK_ID_BUREAU', as_index=False).agg({'STATUS_1':'count','MONTHS_BALANCE':min,\\\n",
    "                                                                                 'STATUS_C':sum,'STATUS_0':sum,'STATUS_X':sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_data_grouped = bureau_balance_data_grouped.rename(columns={'STATUS_1':'BALANCE_COUNT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_data_grouped['STATUS_X_RATIO'] = bureau_balance_data_grouped['STATUS_X'] / bureau_balance_data_grouped['BALANCE_COUNT'].astype(float)\n",
    "bureau_balance_data_grouped['STATUS_C_RATIO'] = bureau_balance_data_grouped['STATUS_C'] / bureau_balance_data_grouped['BALANCE_COUNT'].astype(float)\n",
    "bureau_balance_data_grouped['STATUS_0_RATIO'] = bureau_balance_data_grouped['STATUS_0'] / bureau_balance_data_grouped['BALANCE_COUNT'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_data = bureau_data.merge(bureau_balance_data_grouped, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_data[['MONTHS_BALANCE', 'STATUS_X', 'STATUS_C', 'BALANCE_COUNT', 'STATUS_0', 'STATUS_X_RATIO','STATUS_C_RATIO', 'STATUS_0_RATIO']] = bureau_data[['MONTHS_BALANCE', 'STATUS_X', 'STATUS_C', 'BALANCE_COUNT', 'STATUS_0', 'STATUS_X_RATIO','STATUS_C_RATIO', 'STATUS_0_RATIO']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Bureau Data #####\n",
    "bureau_data_grouped = bureau_data.select_dtypes(exclude='object').drop('SK_ID_BUREAU', axis = 1).groupby('SK_ID_CURR').sum()\n",
    "#bureau_data_grouped.columns = ['_'.join(col) if col != ('SK_ID_CURR', '') else col[0] for col in bureau_data_grouped.columns]\n",
    "bureau_data_grouped = bureau_data_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Past Loan Count\n",
    "loan_count = bureau_data[['SK_ID_CURR','SK_ID_BUREAU']].groupby('SK_ID_CURR', \\\n",
    "                                                   as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU':'LOAN_COUNT'})\n",
    "\n",
    "bureau_data_grouped = bureau_data_grouped.merge(loan_count, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique Loan Types\n",
    "unique_loan_count = bureau_data[['SK_ID_CURR','CREDIT_TYPE']].groupby('SK_ID_CURR',\\\n",
    "                                                                      as_index=False).agg({'CREDIT_TYPE':'nunique'}).rename(columns={'CREDIT_TYPE':'UNIQUE_CREDIT_TYPES'})\n",
    "\n",
    "bureau_data_grouped = bureau_data_grouped.merge(unique_loan_count, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Active Loans\n",
    "bureau_data['CREDIT_ACTIVE_BINARY'] = bureau_data['CREDIT_ACTIVE'].apply(lambda x: 1 if x == 'Active' else 0)\n",
    "\n",
    "active_loan_count = bureau_data[['SK_ID_CURR','CREDIT_ACTIVE_BINARY']].groupby('SK_ID_CURR', \\\n",
    "                                                   as_index=False)['CREDIT_ACTIVE_BINARY'].sum().rename(columns = {'CREDIT_ACTIVE_BINARY':'ACTIVE_LOANS'})\n",
    "\n",
    "bureau_data_grouped = bureau_data_grouped.merge(active_loan_count, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Days Between Successive Past Applications\n",
    "grp = bureau_data[['SK_ID_CURR', 'SK_ID_BUREAU', 'DAYS_CREDIT']].groupby(by = ['SK_ID_CURR'])\n",
    "grp1 = grp.apply(lambda x: x.sort_values(['DAYS_CREDIT'], ascending = False)).reset_index(drop = True)\n",
    "\n",
    "grp1['DAYS_CREDIT1'] = grp1['DAYS_CREDIT']*-1\n",
    "grp1['DAYS_DIFF'] = grp1.groupby(by = ['SK_ID_CURR'])['DAYS_CREDIT1'].diff()\n",
    "grp1['DAYS_DIFF'] = grp1['DAYS_DIFF'].fillna(0).astype('uint32')\n",
    "del grp1['DAYS_CREDIT1'], grp1['DAYS_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_app_days = grp1.groupby('SK_ID_CURR', as_index=False)['DAYS_DIFF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_data_grouped = bureau_data_grouped.merge(past_app_days, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days Credit Expires\n",
    "bureau_data['CREDIT_ENDDATE_BINARY'] = bureau_data['DAYS_CREDIT_ENDDATE'].apply(lambda x: 0 if x < 0 else 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = bureau_data.loc[bureau_data['CREDIT_ENDDATE_BINARY'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = B1[['SK_ID_CURR', 'SK_ID_BUREAU', 'DAYS_CREDIT_ENDDATE']].groupby(by = ['SK_ID_CURR'])\n",
    "# Sort the values of CREDIT_ENDDATE for each customer ID \n",
    "grp1 = grp.apply(lambda x: x.sort_values(['DAYS_CREDIT_ENDDATE'], ascending = True)).reset_index(drop = True)\n",
    "del grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1['DAYS_ENDDATE_DIFF'] = grp1.groupby(by = ['SK_ID_CURR'])['DAYS_CREDIT_ENDDATE'].diff()\n",
    "grp1['DAYS_ENDDATE_DIFF'] = grp1['DAYS_ENDDATE_DIFF'].fillna(0).astype('uint32')\n",
    "del grp1['DAYS_CREDIT_ENDDATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_expires_days = grp1.groupby('SK_ID_CURR', as_index = False)['DAYS_ENDDATE_DIFF'].mean()\n",
    "\n",
    "bureau_data_grouped = bureau_data_grouped.merge(credit_expires_days, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Active Loans\n",
    "bureau_data_grouped['ACTIVE_LOAN_PERC'] = bureau_data_grouped['ACTIVE_LOANS'] / bureau_data_grouped['LOAN_COUNT'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Credit Card Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_one_hot = pd.concat([cc_data['SK_ID_PREV'], \\\n",
    "                            pd.get_dummies(cc_data.select_dtypes(include=['object']), drop_first = True)],\\\n",
    "                            axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_one_hot = cc_data_one_hot.drop(['NAME_CONTRACT_STATUS_Approved','NAME_CONTRACT_STATUS_Demand','NAME_CONTRACT_STATUS_Demand',\\\n",
    "                      'NAME_CONTRACT_STATUS_Refused','NAME_CONTRACT_STATUS_Sent proposal','NAME_CONTRACT_STATUS_Signed'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_one_hot_grouped = cc_data_one_hot.groupby('SK_ID_PREV', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_numeric_grouped = cc_data.select_dtypes(exclude=['object']).groupby('SK_ID_PREV', as_index = False).agg(['count', sum, 'mean', min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_numeric_grouped.columns = ['_CC_'.join(col) if col != ('SK_ID_PREV', '') else col[0] for col in cc_data_numeric_grouped.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cols = filter(lambda x: x[-5:] != 'count' and x[0:10] != 'SK_ID_CURR', cc_data_numeric_grouped.columns.tolist())\n",
    "filtered_cols.insert(0, 'MONTHS_BALANCE_CC_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_numeric_grouped_filtered = cc_data_numeric_grouped[filtered_cols].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data_grouped = cc_data_numeric_grouped_filtered.merge(cc_data_one_hot_grouped, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_dummies = pd.get_dummies(prev_app_data[['NAME_CONTRACT_TYPE','FLAG_LAST_APPL_PER_CONTRACT','NAME_CONTRACT_STATUS',\\\n",
    "                                       'NAME_PAYMENT_TYPE','CODE_REJECT_REASON','NAME_TYPE_SUITE','NAME_CLIENT_TYPE',\\\n",
    "                                       'NAME_PORTFOLIO','CHANNEL_TYPE','NAME_YIELD_GROUP','PRODUCT_COMBINATION']]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_dummies = prev_app_data_dummies[['PRODUCT_COMBINATION_Cash X-Sell: middle','NAME_PORTFOLIO_Cards','CODE_REJECT_REASON_HC','NAME_CONTRACT_TYPE_Revolving loans','CHANNEL_TYPE_Stone','NAME_TYPE_SUITE_Family','PRODUCT_COMBINATION_POS mobile with interest','PRODUCT_COMBINATION_POS household with interest','PRODUCT_COMBINATION_Cash','NAME_CONTRACT_STATUS_Refused','NAME_CLIENT_TYPE_New','NAME_CONTRACT_STATUS_Canceled','NAME_YIELD_GROUP_low_normal','NAME_YIELD_GROUP_high','NAME_PORTFOLIO_XNA','NAME_YIELD_GROUP_middle','NAME_PORTFOLIO_Cash','CHANNEL_TYPE_Country-wide','NAME_TYPE_SUITE_Unaccompanied','NAME_YIELD_GROUP_XNA','NAME_PAYMENT_TYPE_XNA','NAME_PORTFOLIO_POS','CHANNEL_TYPE_Credit and cash offices','NAME_CONTRACT_TYPE_Consumer loans','NAME_CONTRACT_TYPE_Cash loans','NAME_PAYMENT_TYPE_Cash through the bank','NAME_CONTRACT_STATUS_Approved','NAME_CLIENT_TYPE_Repeater','CODE_REJECT_REASON_XAP','FLAG_LAST_APPL_PER_CONTRACT_Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data = pd.concat([prev_app_data.select_dtypes(exclude=['object']), prev_app_data_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_merged = prev_app_data.merge(cc_data_grouped, how = 'left', left_on = 'SK_ID_PREV', right_on = 'SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_data_grouped = installments_data.groupby('SK_ID_PREV', as_index = False).agg(['count', sum, 'mean', min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_data_grouped.columns = ['_INST_'.join(col) if col != ('SK_ID_PREV', '') else col[0] for col in installments_data_grouped.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_data_grouped = installments_data_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cols = filter(lambda x: x[-5:] != 'count' and x[0:10] != 'SK_ID_CURR', installments_data_grouped.columns.tolist())\n",
    "filtered_cols.insert(0, 'SK_ID_CURR_INST_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_data_grouped = installments_data_grouped[filtered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_merged = prev_app_data_merged.merge(installments_data_grouped, how = 'left', left_on = 'SK_ID_PREV', right_on = 'SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_data = pd.get_dummies(pos_cash_balance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_data = pos_cash_balance_data.drop(['NAME_CONTRACT_STATUS_Amortized debt',\\\n",
    "                                                    'NAME_CONTRACT_STATUS_Approved','NAME_CONTRACT_STATUS_Canceled','NAME_CONTRACT_STATUS_Demand',\\\n",
    "                                                    'NAME_CONTRACT_STATUS_Returned to the store','NAME_CONTRACT_STATUS_XNA'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_data_grouped = pos_cash_balance_data.groupby('SK_ID_PREV', as_index=False).agg(['count', sum, 'mean', min, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_data_grouped.columns = ['_POS_'.join(col) if col != ('SK_ID_PREV', '') else col[0] for col in pos_cash_balance_data_grouped.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_data_grouped = pos_cash_balance_data_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cols = filter(lambda x: x[-5:] != 'count' and x[0:10] != 'SK_ID_CURR', pos_cash_balance_data_grouped.columns.tolist())\n",
    "filtered_cols.insert(0, 'SK_ID_CURR_POS_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance_data_grouped = pos_cash_balance_data_grouped[filtered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_merged = prev_app_data_merged.merge(pos_cash_balance_data_grouped, how = 'left', left_on = 'SK_ID_PREV', right_on = 'SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cols = filter(lambda x: x[-5:] != 'count' and x[0:10] != 'SK_ID_CURR', bureau_data_grouped.columns.tolist())\n",
    "filtered_cols.insert(0, 'SK_ID_BUREAU_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_hot = pd.concat([train.select_dtypes(exclude=['object']), train_dummies], axis = 1)\n",
    "\n",
    "test_one_hot = pd.concat([test.select_dtypes(exclude=['object']), test_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = train_one_hot.merge(bureau_data_grouped, how = 'left', left_on = 'SK_ID_CURR', right_on = 'SK_ID_CURR')\n",
    "\n",
    "test_merged = test_one_hot.merge(bureau_data_grouped, how = 'left', left_on = 'SK_ID_CURR', right_on = 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_subset = prev_app_data_merged[prev_app_data_merged.columns.tolist()].drop('SK_ID_PREV', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_data_grouped = prev_app_data_subset.groupby('SK_ID_CURR', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prev_app_data_grouped.columns = ['_'.join(col) if col != ('SK_ID_CURR', '') else col[0] for col in prev_app_data_grouped.columns]\n",
    "#prev_app_data_grouped = prev_app_data_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = train_merged.merge(prev_app_data_grouped, how = 'left', left_on = 'SK_ID_CURR', right_on = 'SK_ID_CURR')\n",
    "\n",
    "test_merged = test_merged.merge(prev_app_data_grouped, how = 'left', left_on = 'SK_ID_CURR', right_on = 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_car_median = train_merged.OWN_CAR_AGE.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_car_missing(x):\n",
    "    if x['FLAG_OWN_CAR'] == 'N':\n",
    "        return 28\n",
    "    elif x['FLAG_OWN_CAR'] == 'Y' and pd.isnull(x['OWN_CAR_AGE']):\n",
    "        return own_car_median\n",
    "    else:\n",
    "        return x['OWN_CAR_AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_subset = train_merged.dropna(thresh=len(train_merged) - 200000000, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_subset['AMT_CREDIT_y'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_subset.info(verbose=True, null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_corr_subset = train_merged_subset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(column_corr_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_corr = train_merged_subset.corr()['TARGET'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_corr_subset = col_corr[(col_corr >= 0.03) | (col_corr < -0.035)].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_corr_subset.remove('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_corr_subset.remove('CODE_GENDER_XNA')\n",
    "#column_corr_subset.remove('NAME_FAMILY_STATUS_Unknown')\n",
    "#column_corr_subset.remove('NAME_INCOME_TYPE_Maternity leave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train_merged_subset[column_corr_subset]\n",
    "\n",
    "test_subset = test_merged[column_corr_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer()\n",
    "imputer.fit(train_subset)\n",
    "train_merged_imputed = pd.DataFrame(imputer.transform(train_subset), columns = train_subset.columns)\n",
    "test_merged_imputed = pd.DataFrame(imputer.transform(test_subset), columns = train_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_imputed['DAYS_EMPLOYED_^2'] = train_merged_imputed['DAYS_EMPLOYED'] ** 2\n",
    "#train_merged_imputed['AMT_GOODS_PRICE_^2'] = train_merged_imputed['AMT_GOODS_PRICE'] ** 2\n",
    "train_merged_imputed['DAYS_CREDIT^2'] = train_merged_imputed['DAYS_CREDIT'] ** 2\n",
    "#train_merged_imputed['DAYS_CREDIT_median^2'] = train_merged_imputed['DAYS_CREDIT_median'] ** 2\n",
    "train_merged_imputed['DAYS_BIRTH_^2'] = train_merged_imputed['DAYS_BIRTH'] ** 2\n",
    "train_merged_imputed['REGION_RATING_CLIENT_W_CITY_^2'] = train_merged_imputed['REGION_RATING_CLIENT_W_CITY'] ** 2\n",
    "train_merged_imputed['REGION_RATING_CLIENT_^2'] = train_merged_imputed['REGION_RATING_CLIENT'] ** 2\n",
    "train_merged_imputed['NAME_INCOME_TYPE_Working_^2'] = train_merged_imputed['NAME_INCOME_TYPE_Working'] ** 2\n",
    "train_merged_imputed['DAYS_LAST_PHONE_CHANGE_^2'] = train_merged_imputed['DAYS_LAST_PHONE_CHANGE'] ** 2\n",
    "train_merged_imputed['EXT_SOURCE_1_^2'] = train_merged_imputed['EXT_SOURCE_1'] ** 2\n",
    "train_merged_imputed['EXT_SOURCE_2_^2'] = train_merged_imputed['EXT_SOURCE_2'] ** 2\n",
    "train_merged_imputed['EXT_SOURCE_3_^2'] = train_merged_imputed['EXT_SOURCE_3'] ** 2\n",
    "train_merged_imputed['NAME_EDUCATION_TYPE_Higher education_^2'] = train_merged_imputed['NAME_EDUCATION_TYPE_Higher education'] ** 2\n",
    "train_merged_imputed['CODE_GENDER_F_^2']= train_merged_imputed['CODE_GENDER_F'] ** 2\n",
    "\n",
    "train_merged_imputed['DAYS_EMPLOYED_^3'] = train_merged_imputed['DAYS_EMPLOYED'] ** 3\n",
    "#train_merged_imputed['AMT_GOODS_PRICE_^3'] = train_merged_imputed['AMT_GOODS_PRICE'] ** 3\n",
    "train_merged_imputed['DAYS_CREDIT^3'] = train_merged_imputed['DAYS_CREDIT'] ** 3\n",
    "#train_merged_imputed['DAYS_CREDIT_median^3'] = train_merged_imputed['DAYS_CREDIT_median'] ** 3\n",
    "train_merged_imputed['DAYS_BIRTH_^3'] = train_merged_imputed['DAYS_BIRTH'] ** 3\n",
    "train_merged_imputed['REGION_RATING_CLIENT_W_CITY_^3'] = train_merged_imputed['REGION_RATING_CLIENT_W_CITY'] ** 3\n",
    "train_merged_imputed['REGION_RATING_CLIENT_^3'] = train_merged_imputed['REGION_RATING_CLIENT'] ** 3\n",
    "train_merged_imputed['NAME_INCOME_TYPE_Working_^3'] = train_merged_imputed['NAME_INCOME_TYPE_Working'] ** 3\n",
    "train_merged_imputed['DAYS_LAST_PHONE_CHANGE_^3'] = train_merged_imputed['DAYS_LAST_PHONE_CHANGE'] ** 3\n",
    "train_merged_imputed['EXT_SOURCE_1_^3'] = train_merged_imputed['EXT_SOURCE_1'] ** 3\n",
    "train_merged_imputed['EXT_SOURCE_2_^3'] = train_merged_imputed['EXT_SOURCE_2'] ** 3\n",
    "train_merged_imputed['EXT_SOURCE_3_^3'] = train_merged_imputed['EXT_SOURCE_3'] ** 3\n",
    "train_merged_imputed['NAME_EDUCATION_TYPE_Higher education_^3'] = train_merged_imputed['NAME_EDUCATION_TYPE_Higher education'] ** 3\n",
    "train_merged_imputed['CODE_GENDER_F_^3']= train_merged_imputed['CODE_GENDER_F'] ** 3\n",
    "\n",
    "test_merged_imputed['DAYS_EMPLOYED_^2'] = test_merged_imputed['DAYS_EMPLOYED'] ** 2\n",
    "#test_merged_imputed['AMT_GOODS_PRICE_^2'] = test_merged_imputed['AMT_GOODS_PRICE'] ** 2\n",
    "test_merged_imputed['DAYS_CREDIT_^2'] = test_merged_imputed['DAYS_CREDIT'] ** 2\n",
    "#test_merged_imputed['DAYS_CREDIT_median^2'] = test_merged_imputed['DAYS_CREDIT_median'] ** 2\n",
    "test_merged_imputed['DAYS_BIRTH_^2'] = test_merged_imputed['DAYS_BIRTH'] ** 2\n",
    "test_merged_imputed['REGION_RATING_CLIENT_W_CITY_^2'] = test_merged_imputed['REGION_RATING_CLIENT_W_CITY'] ** 2\n",
    "test_merged_imputed['REGION_RATING_CLIENT_^2'] = test_merged_imputed['REGION_RATING_CLIENT'] ** 2\n",
    "test_merged_imputed['NAME_INCOME_TYPE_Working_^2'] = test_merged_imputed['NAME_INCOME_TYPE_Working'] ** 2\n",
    "test_merged_imputed['DAYS_LAST_PHONE_CHANGE_^2'] = test_merged_imputed['DAYS_LAST_PHONE_CHANGE'] ** 2\n",
    "test_merged_imputed['EXT_SOURCE_1_^2'] = test_merged_imputed['EXT_SOURCE_1'] ** 2\n",
    "test_merged_imputed['EXT_SOURCE_2_^2'] = test_merged_imputed['EXT_SOURCE_2'] ** 2\n",
    "test_merged_imputed['EXT_SOURCE_3_^2'] = test_merged_imputed['EXT_SOURCE_3'] ** 2\n",
    "test_merged_imputed['NAME_EDUCATION_TYPE_Higher education_^2'] = test_merged_imputed['NAME_EDUCATION_TYPE_Higher education'] ** 2\n",
    "test_merged_imputed['CODE_GENDER_F_^2']= test_merged_imputed['CODE_GENDER_F'] ** 2\n",
    "\n",
    "test_merged_imputed['DAYS_EMPLOYED_^3'] = test_merged_imputed['DAYS_EMPLOYED'] ** 3\n",
    "#test_merged_imputed['AMT_GOODS_PRICE_^3'] = test_merged_imputed['AMT_GOODS_PRICE'] ** 3\n",
    "test_merged_imputed['DAYS_CREDIT^3'] = test_merged_imputed['DAYS_CREDIT'] ** 3\n",
    "#test_merged_imputed['DAYS_CREDIT_median^3'] = test_merged_imputed['DAYS_CREDIT_median'] ** 3\n",
    "test_merged_imputed['DAYS_BIRTH_^3'] = test_merged_imputed['DAYS_BIRTH'] ** 3\n",
    "test_merged_imputed['REGION_RATING_CLIENT_W_CITY_^3'] = test_merged_imputed['REGION_RATING_CLIENT_W_CITY'] ** 3\n",
    "test_merged_imputed['REGION_RATING_CLIENT_^3'] = test_merged_imputed['REGION_RATING_CLIENT'] ** 3\n",
    "test_merged_imputed['NAME_INCOME_TYPE_Working_^3'] = test_merged_imputed['NAME_INCOME_TYPE_Working'] ** 3\n",
    "test_merged_imputed['DAYS_LAST_PHONE_CHANGE_^3'] = test_merged_imputed['DAYS_LAST_PHONE_CHANGE'] ** 3\n",
    "test_merged_imputed['EXT_SOURCE_1_^3'] = test_merged_imputed['EXT_SOURCE_1'] ** 3\n",
    "test_merged_imputed['EXT_SOURCE_2_^3'] = test_merged_imputed['EXT_SOURCE_2'] ** 3\n",
    "test_merged_imputed['EXT_SOURCE_3_^3'] = test_merged_imputed['EXT_SOURCE_3'] ** 3\n",
    "test_merged_imputed['NAME_EDUCATION_TYPE_Higher education_^3'] = test_merged_imputed['NAME_EDUCATION_TYPE_Higher education'] ** 3\n",
    "test_merged_imputed['CODE_GENDER_F_^3']= test_merged_imputed['CODE_GENDER_F'] ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_transformer = PolynomialFeatures(degree = 1)\n",
    "poly_transformer.fit(train_merged_imputed)\n",
    "train_poly_features = poly_transformer.transform(train_merged_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_poly = pd.DataFrame(train_poly_features, columns = poly_transformer.get_feature_names(\n",
    "    input_features = train_merged_imputed.columns.tolist()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_poly_features = poly_transformer.transform(test_merged_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_poly = pd.DataFrame(test_poly_features, columns = poly_transformer.get_feature_names(input_features = test_merged_imputed.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train_subset_poly)\n",
    "train_scaled = scaler.transform(train_subset_poly)\n",
    "test_scaled = scaler.transform(test_subset_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(iterations = 1000, random_state = 42, learning_rate = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_model.fit(train_scaled, train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#xgb_model = XGBClassifier(n_estimators = 500, silent=True, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_model.fit(train_scaled, train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_cat = pd.DataFrame(xgb_model.predict_proba(test_scaled))\n",
    "submission_cat = pd.concat([test.SK_ID_CURR, test_y_cat], axis=1).drop(0, axis = 1)\n",
    "submission_cat.columns = ['SK_ID_CURR', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cat.to_csv('xgb_model10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_cat['Target'] = submission_cat['Target'].apply(lambda x: (x - min_sub_cat) / (max_sub_cat - min_sub_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_submission = pd.read_csv('cat_lr75.csv')\n",
    "xgb_submission = pd.read_csv('xgb1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cat['Target'] = (submission_cat['Target']+ xgb_submission['Target']) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cat.to_csv('combined11.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lightgbm.Dataset(train_scaled, train.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "#                       valid_sets=test_data,\n",
    "                       num_boost_round=10000,\n",
    "#                       early_stopping_rounds=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(model.predict(test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgbm = pd.concat([test.SK_ID_CURR, preds], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgbm.columns = ['SK_ID_CURR', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cat.to_csv('lgbm2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_10 = pd.read_csv('combined10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_10['Target'] = (combined_10['Target'] + submission_cat['Target']) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_10.to_csv('new_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
